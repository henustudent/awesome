# RVOS：
## RVOS with Language:
### MeViS: A Large-scale Benchmark for Video Segmentation with Motion Expressions：
提出了一个名为MeViS的大规模数据集，其中包含大量的运动表达式来指示复杂环境中的目标对象。基准测试的目标是提供一个平台，支持开发有效的语言引导视频分割算法，利用运动表达式作为复杂视频场景中对象分割的主要线索。语言引导的视频分割是一个新兴领域，涉及使用自然语言表达来分割和跟踪目标对象。该领域传统上是半监督视频对象分割的一个子分支，其中引用表达式用于描述目标对象。
### RefVOS: A Closer Look at Referring Expressions for Video Object Segmentation：
使用引用表达式(语言引导的VOS)的视频对象分割的任务是，给定一个语言短语和一个视频，为该短语所引用的对象生成二进制掩码
我们利用RefVOS解决了语言引导的图像分割和语言引导的视频对象分割任务，ref vos是我们的端到端深度神经网络，利用BERT语言表示对短语进行编码。

### Deeply Interleaved Two-Stream Encoder for Referring Video Segmentation
本文旨在解决一个称为参考视频分割的任务。给定一个视频片段和一个引用表达式，该任务的目标是根据查询语言的描述分割视频序列中相应的实体(对象)。
参考视频分割的目的是分割相应的语言表达所描述的视频对象。为了解决这一任务，我们首先设计了一个双流编码器来分层提取基于CNN的视觉特征和基于transformer的语言特征，并在编码器中多次插入视觉-语言相互指导(VLMG)模块，以促进多模态特征的分层渐进融合。与现有的多模态融合方法相比，该双流编码器考虑了多粒度语言环境，并借助VLGM实现了模态间的深度交织。为了促进帧间的时间对齐，我们进一步提出了语言引导的多尺度动态滤波(LMDF)模块来增强时间一致性，该模块使用语言引导的时空特征来生成一组位置特定的动态滤波器，以更加灵活有效地更新当前帧的特征。

### MED-VT: Multiscale Encoder-Decoder Video Transformer with Application to Object Segmentation
我们提出了一种统一的多尺度编解码转换器，该转换器专注于视频中的密集预测任务。在编码时，其尺度内和尺度间的注意机制使其能够捕获空间、时间和整合的时空信息。在解码时，它引入了可学习的从粗到精的查询，允许精确的目标描绘，同时通过转导学习在预测的掩码之间强制时间一致性。MED-VT在任务自动视频对象分割(AVOS)的应用，AVOS将视频中的主要前景对象从背景中分离出来，而无需任何监督，即无需感兴趣对象的信息。AVOS没有受益于任何每视频初始化。由于缺乏先验信息，解决方案必须利用外观(如颜色和形状)以及动作来收集尽可能多的信息。
MED-VT应对这些挑战。其内部和之间的规模注意机制捕捉外观和运动信息，以及生产时间的一致性。其可学习的由粗到细的查询允许在更深的层加载语义信息，以引导更精细的尺度特征，从而精确地描绘对象。它通过多对多标签传播的直推式学习确保了时间一致的预测。

## RVOS with Audio:
### Wnet: Audio-Guided Video Object Segmentation via Wavelet-Based Cross-Modal Denoising Networks

音频引导的视频对象分割是视觉分析和编辑中的一个具有挑战性的问题，它根据参考音频表达式自动将视频序列中的前景对象从背景中分离出来。然而，由于缺乏对音视频交互内容的语义表示进行建模，现有的指代视频对象分割工作主要集中在基于文本的指代表达式的指导上，本文从端到端去噪编解码网络学习的角度考虑音频引导的视频语义分割问题。提出基于小波的编码器网络来学习具有音频形式查询的视频内容的跨模态表示。还构建了一个大规模的音频引导视频对象分割数据集
提出了基于小波的编码器网络来学习具有音频形式查询的视频内容的跨模态表示。具体来说，采用多头跨模态注意层来探索视频和查询内容之间的潜在关系。二维离散小波变换被合并到变换编码器中以分解音频-视频特征。接下来，在跨模态注意层之后最大化编码特征和多模态特征之间的互信息，以增强音频引导。然后，开发了一个自无关解码器网络，通过频域变换生成目标掩模。


# AVOS
### Automatic Video Object Segmentation Based on Visual and Motion Saliency
自动视频对象分割(AVOS)是将视频中的前景对象从背景中自动分离出来，现存的方法通常采用现有图像显著性模型与运动线索的结合，但这些方法的性能不足以指导视频中精确的对象分割。
本文中开发一个显著的目标检测方法，具有更高的检测性能和更少的要求。该方法使用加权多流形排序算法来计算每一帧中的视觉显著性。然后计算运动线索来估计运动显著性和定位先验。采用新的能量函数来估计跨所有帧的超像素级对象标记，这保持了图像中显著对象的清晰外观和形状
流形排序(Manifold Ranking ):流形排序是衡量查询和剩余数据之间的相关性，通常用加权图表示。查询被分配一个正值，并且剩余的节点相对于查询被排序。在流形排序中，图像被映射到一个有n个节点的图。每个节点对应于图像位置，即图像超像素。



Related Works

